{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Porto Seguroâ€™s LooperEmbedNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI3NTEQioD4o",
        "colab_type": "code",
        "outputId": "9481da61-cf8c-44dd-8930-e379bfc55333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "CysrHbxsn_ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import Imputer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import os\n",
        "from sklearn.metrics import classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import seaborn as sns, numpy as np\n",
        "from scipy.stats import norm\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,auc\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# print(os.listdir(\"../input/\"))\n",
        "df = pd.read_csv('/content/drive/My Drive/porto_train.csv')\n",
        "df.drop(['id'],axis=1,inplace=True)\n",
        "\n",
        "def eval_gini(y_true, y_prob):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_true = y_true[np.argsort(y_prob)]\n",
        "    ntrue = 0\n",
        "    gini = 0\n",
        "    delta = 0\n",
        "    n = len(y_true)\n",
        "    for i in range(n-1, -1, -1):\n",
        "        y_i = y_true[i]\n",
        "        ntrue += y_i\n",
        "        gini += y_i * delta\n",
        "        delta += 1 - y_i\n",
        "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
        "    return gini\n",
        "\n",
        "\n",
        "def create_meta(df):    \n",
        "    data = []\n",
        "    for f in df.columns:\n",
        "        # Defining the role\n",
        "        if f == 'target':\n",
        "            role = 'target'\n",
        "        elif f == 'id':\n",
        "            role = 'id'\n",
        "        else:\n",
        "            role = 'input'\n",
        "\n",
        "        # Defining the level\n",
        "        if 'bin' in f or f == 'target':\n",
        "            level = 'binary'\n",
        "        elif 'cat' in f or f == 'id':\n",
        "            level = 'nominal'\n",
        "        elif df[f].dtype == float:\n",
        "            level = 'interval'\n",
        "        elif df[f].dtype == int:\n",
        "            level = 'ordinal'\n",
        "\n",
        "        # Initialize keep to True for all variables except for id\n",
        "        keep = True\n",
        "        if f == 'id':\n",
        "            keep = False\n",
        "\n",
        "        # Defining the data type \n",
        "        dtype = df[f].dtype\n",
        "\n",
        "        # Creating a Dict that contains all the metadata for the variable\n",
        "        f_dict = {\n",
        "            'varname': f,\n",
        "            'role': role,\n",
        "            'level': level,\n",
        "            'keep': keep,\n",
        "            'dtype': dtype\n",
        "        }\n",
        "        data.append(f_dict)\n",
        "\n",
        "    meta = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype'])\n",
        "    meta.set_index('varname', inplace=True)\n",
        "    return(meta)\n",
        "# Any results you write to the current directory are saved as output.\n",
        "meta=create_meta(df)\n",
        "meta.drop(['target'],inplace=True)\n",
        "meta.drop(['keep'],axis=1,inplace=True)\n",
        "meta.drop(['role'],axis=1,inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7baugYZrn_pk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeDpktK-n_qr",
        "colab_type": "text"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pxSxg5X2n_qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/porto_train.csv')\n",
        "df.drop(['id'],axis=1,inplace=True)\n",
        "orig=df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "c_d1zSifn_qt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=df.iloc[:100000,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dEk0PZuwn_q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "R3TUjNVsn_q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# removing calc cols increases baseline xgboost from 0.22 to 0.23227886570\n",
        "for e in df.columns:\n",
        "    if 'calc' in e: df.drop(e,axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "L3Ubm-XOn_q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta=create_meta(df)\n",
        "meta.drop(['target'],inplace=True)\n",
        "meta.drop(['keep'],axis=1,inplace=True)\n",
        "meta.drop(['role'],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "p_2a_O_Yn_q9",
        "colab_type": "code",
        "outputId": "3943b19e-8649-4572-fa98-89abf7790fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(df)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "j3bn65SMn_rI",
        "colab_type": "code",
        "outputId": "2ff612d4-1dcd-4404-baba-32edc0501994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Handle missing vals first\n",
        "\n",
        "N=np.shape(df)[0]\n",
        "N"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "m2H-d5GJn_rK",
        "colab_type": "code",
        "outputId": "da3fe24c-1112-4696-8f16-5e93600044ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#missing continous\n",
        "for e in meta[meta.level=='interval'].index :  \n",
        "    if np.min(df[e])==-1:\n",
        "        print(e, 'has', np.sum(df[e]==-1),'missing vals which is ',np.sum(df[e]==-1)/N ,'from 1' ) # consdier log transform for 2\n",
        "        df[e][df[e]==-1]=np.mean(df[e])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ps_reg_03 has 18229 missing vals which is  0.18229 from 1\n",
            "ps_car_14 has 7065 missing vals which is  0.07065 from 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "q48kvlqSn_rP",
        "colab_type": "code",
        "outputId": "80fe2ef1-4326-4d89-d302-247b870d56e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#missing Ordinal\n",
        "# Can we just assign ordinal to highest? Maybe 2 would be better....\n",
        "# only ps_car_11 which does have a class majority at 3\n",
        "print(df['ps_car_11'].value_counts())\n",
        "df['ps_car_11'][df['ps_car_11']==-1]=3"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3    53479\n",
            "2    31862\n",
            "1    10242\n",
            "0     4417\n",
            "Name: ps_car_11, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8M57CFcyn_rU",
        "colab_type": "code",
        "outputId": "e8e908ad-5ba9-4041-8fe9-0c84d0929a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "#missing categorical\n",
        "from scipy import stats\n",
        "\n",
        "mode_r=[\"ps_ind_02_cat\",\"ps_ind_04_cat\",\"ps_ind_05_cat\",\"ps_car_02_cat\",\"ps_car_07_cat\",\"ps_car_09_cat\",'ps_car_11']\n",
        "for e in mode_r:\n",
        "    print(e, 'has', np.sum(df[e]==-1),'missing vals which is ',100*np.sum(df[e]==-1)/N ,'%' )\n",
        "    df[e][df[e]==-1]=stats.mode(df[e])[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ps_ind_02_cat has 31 missing vals which is  0.031 %\n",
            "ps_ind_04_cat has 13 missing vals which is  0.013 %\n",
            "ps_ind_05_cat has 960 missing vals which is  0.96 %\n",
            "ps_car_02_cat has 1 missing vals which is  0.001 %\n",
            "ps_car_07_cat has 1854 missing vals which is  1.854 %\n",
            "ps_car_09_cat has 85 missing vals which is  0.085 %\n",
            "ps_car_11 has 0 missing vals which is  0.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kj9O-SVsn_rY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop too many missing vars\n",
        "df.drop([\"ps_car_03_cat\",\"ps_car_05_cat\"],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "a9Lrrx2un_rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Make new feat as heavy concentration after 102\n",
        "# sns.countplot(df[\"ps_car_11_cat\"],palette='summer')\n",
        "# plt.show()\n",
        "# print(np.unique(df[\"ps_car_11_cat\"])[:-10]) # last 10\n",
        "\n",
        "# sns.countplot(df[\"ps_car_11_cat\"][df[\"ps_car_11_cat\"]>100],palette='summer')\n",
        "# plt.show()\n",
        " \n",
        "# #Make feat =<102 or >102\n",
        "\n",
        "# df['ps_car_11_cat_bin']=df[\"ps_car_11_cat\"]>102\n",
        "# df['ps_car_11_cat_bin']=df['ps_car_11_cat_bin'].astype(int)\n",
        "# print(df.ps_car_11_cat_bin[:10])\n",
        "\n",
        "# sns.countplot(df[\"ps_car_11_cat_bin\"],palette='summer')\n",
        "# plt.show()\n",
        "\n",
        "# # df.drop(['ps_car_11_cat'],axis=1,inplace=True) # drop this as it has wayyy to many categories 104"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BYoA3BQAn_rf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#outliers\n",
        "# We can clip outliers, or create a feat to indicate outlier presence, or impute vals\n",
        "\n",
        "def IQR_outlier(df,e):\n",
        "    quartile_1,quartile_3 = np.percentile(df[e],[25,75])\n",
        "    IQR=quartile_3-quartile_1\n",
        "    upper_lim=quartile_3+1.5*IQR\n",
        "    lower_lim=quartile_1-1.5*IQR\n",
        "\n",
        "    print(e, ' has',np.shape(df[e][df[e]>upper_lim])[0],' outliers which is ',100*np.shape(df[e][df[e]>upper_lim])[0]/N ,'%' )\n",
        "    df['ps_reg_02'][df['ps_reg_02']>upper_lim]=upper_lim\n",
        "    \n",
        "    return(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VL1_njSxn_rh",
        "colab_type": "code",
        "outputId": "2e584941-a9a9-489a-ffa7-c269efec90bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "outlier_list=['ps_reg_02',\"ps_reg_03\"\n",
        ",\"ps_car_12\"\n",
        ",\"ps_car_13\"\n",
        "]\n",
        "for e in outlier_list:\n",
        "    df=IQR_outlier(df,e)#36793"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ps_reg_02  has 6196  outliers which is  6.196 %\n",
            "ps_reg_03  has 2651  outliers which is  2.651 %\n",
            "ps_car_12  has 2543  outliers which is  2.543 %\n",
            "ps_car_13  has 4449  outliers which is  4.449 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0ZXO0bgGn_rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta=create_meta(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3KrJG71n_rn",
        "colab_type": "text"
      },
      "source": [
        "# ------One hot Encode Branch----- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "H_dHWMkcn_ro",
        "colab_type": "code",
        "outputId": "2506532a-192a-46a2-d6c2-3f615e79513b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "v = meta[meta.level=='nominal'].index\n",
        "print('Before dummification we have {} variables in train'.format(df.shape[1]))\n",
        "train = pd.get_dummies(df, columns=v, drop_first=True)\n",
        "print('After dummification we have {} variables in train'.format(train.shape[1]))\n",
        "\n",
        "# 104 of these are from ps_car_11_cat, we can remove that col or something else"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before dummification we have 36 variables in train\n",
            "After dummification we have 184 variables in train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5rjYliBln_rp",
        "colab_type": "code",
        "outputId": "876e3271-099d-4f52-e2aa-0bf01c89ba9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ps_ind_01</th>\n",
              "      <th>ps_ind_03</th>\n",
              "      <th>ps_ind_06_bin</th>\n",
              "      <th>ps_ind_07_bin</th>\n",
              "      <th>ps_ind_08_bin</th>\n",
              "      <th>ps_ind_09_bin</th>\n",
              "      <th>ps_ind_10_bin</th>\n",
              "      <th>ps_ind_11_bin</th>\n",
              "      <th>ps_ind_12_bin</th>\n",
              "      <th>ps_ind_13_bin</th>\n",
              "      <th>ps_ind_14</th>\n",
              "      <th>ps_ind_15</th>\n",
              "      <th>ps_ind_16_bin</th>\n",
              "      <th>ps_ind_17_bin</th>\n",
              "      <th>ps_ind_18_bin</th>\n",
              "      <th>ps_reg_01</th>\n",
              "      <th>ps_reg_02</th>\n",
              "      <th>ps_reg_03</th>\n",
              "      <th>ps_car_11</th>\n",
              "      <th>ps_car_12</th>\n",
              "      <th>ps_car_13</th>\n",
              "      <th>ps_car_14</th>\n",
              "      <th>ps_car_15</th>\n",
              "      <th>ps_ind_02_cat_2</th>\n",
              "      <th>ps_ind_02_cat_3</th>\n",
              "      <th>ps_ind_02_cat_4</th>\n",
              "      <th>ps_ind_04_cat_1</th>\n",
              "      <th>ps_ind_05_cat_1</th>\n",
              "      <th>ps_ind_05_cat_2</th>\n",
              "      <th>ps_ind_05_cat_3</th>\n",
              "      <th>ps_ind_05_cat_4</th>\n",
              "      <th>ps_ind_05_cat_5</th>\n",
              "      <th>ps_ind_05_cat_6</th>\n",
              "      <th>ps_car_01_cat_0</th>\n",
              "      <th>ps_car_01_cat_1</th>\n",
              "      <th>ps_car_01_cat_2</th>\n",
              "      <th>ps_car_01_cat_3</th>\n",
              "      <th>ps_car_01_cat_4</th>\n",
              "      <th>ps_car_01_cat_5</th>\n",
              "      <th>...</th>\n",
              "      <th>ps_car_11_cat_65</th>\n",
              "      <th>ps_car_11_cat_66</th>\n",
              "      <th>ps_car_11_cat_67</th>\n",
              "      <th>ps_car_11_cat_68</th>\n",
              "      <th>ps_car_11_cat_69</th>\n",
              "      <th>ps_car_11_cat_70</th>\n",
              "      <th>ps_car_11_cat_71</th>\n",
              "      <th>ps_car_11_cat_72</th>\n",
              "      <th>ps_car_11_cat_73</th>\n",
              "      <th>ps_car_11_cat_74</th>\n",
              "      <th>ps_car_11_cat_75</th>\n",
              "      <th>ps_car_11_cat_76</th>\n",
              "      <th>ps_car_11_cat_77</th>\n",
              "      <th>ps_car_11_cat_78</th>\n",
              "      <th>ps_car_11_cat_79</th>\n",
              "      <th>ps_car_11_cat_80</th>\n",
              "      <th>ps_car_11_cat_81</th>\n",
              "      <th>ps_car_11_cat_82</th>\n",
              "      <th>ps_car_11_cat_83</th>\n",
              "      <th>ps_car_11_cat_84</th>\n",
              "      <th>ps_car_11_cat_85</th>\n",
              "      <th>ps_car_11_cat_86</th>\n",
              "      <th>ps_car_11_cat_87</th>\n",
              "      <th>ps_car_11_cat_88</th>\n",
              "      <th>ps_car_11_cat_89</th>\n",
              "      <th>ps_car_11_cat_90</th>\n",
              "      <th>ps_car_11_cat_91</th>\n",
              "      <th>ps_car_11_cat_92</th>\n",
              "      <th>ps_car_11_cat_93</th>\n",
              "      <th>ps_car_11_cat_94</th>\n",
              "      <th>ps_car_11_cat_95</th>\n",
              "      <th>ps_car_11_cat_96</th>\n",
              "      <th>ps_car_11_cat_97</th>\n",
              "      <th>ps_car_11_cat_98</th>\n",
              "      <th>ps_car_11_cat_99</th>\n",
              "      <th>ps_car_11_cat_100</th>\n",
              "      <th>ps_car_11_cat_101</th>\n",
              "      <th>ps_car_11_cat_102</th>\n",
              "      <th>ps_car_11_cat_103</th>\n",
              "      <th>ps_car_11_cat_104</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.718070</td>\n",
              "      <td>2</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.883679</td>\n",
              "      <td>0.370810</td>\n",
              "      <td>3.605551</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.766078</td>\n",
              "      <td>3</td>\n",
              "      <td>0.316228</td>\n",
              "      <td>0.618817</td>\n",
              "      <td>0.388716</td>\n",
              "      <td>2.449490</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.549986</td>\n",
              "      <td>1</td>\n",
              "      <td>0.316228</td>\n",
              "      <td>0.641586</td>\n",
              "      <td>0.347275</td>\n",
              "      <td>3.316625</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.580948</td>\n",
              "      <td>1</td>\n",
              "      <td>0.374166</td>\n",
              "      <td>0.542949</td>\n",
              "      <td>0.294958</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.525658</td>\n",
              "      <td>0.840759</td>\n",
              "      <td>3</td>\n",
              "      <td>0.316070</td>\n",
              "      <td>0.565832</td>\n",
              "      <td>0.365103</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 184 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  ps_ind_01  ...  ps_car_11_cat_103  ps_car_11_cat_104\n",
              "0       0          2  ...                  0                  0\n",
              "1       0          1  ...                  0                  0\n",
              "2       0          5  ...                  0                  0\n",
              "3       0          0  ...                  0                  1\n",
              "4       0          0  ...                  0                  0\n",
              "\n",
              "[5 rows x 184 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "k9iErqEKn_rq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta=create_meta(train) # we shifted from df to train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pw79ji8Pn_r4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalise continous variables\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "train[meta[meta.level=='interval'].index] = scaler.fit_transform(train[meta[meta.level=='interval'].index])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "El0UrHX2n_sI",
        "colab_type": "code",
        "outputId": "dc206d2b-ef19-4d4d-ffca-d789132e6964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(np.concatenate([ meta[meta.level=='binary'].index,meta[meta.level=='nominal'].index ])),np.shape(meta[meta.level=='interval'].index),np.shape(meta[meta.level=='ordinal'].index)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((172,), (7,), (5,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAZh58ccn_sP",
        "colab_type": "text"
      },
      "source": [
        "![](http://)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3wKaeoJn_t_",
        "colab_type": "text"
      },
      "source": [
        "# Embedding Network "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z64M-JSBFRrB",
        "colab_type": "text"
      },
      "source": [
        "As there is heavy class imbalance, only 3.6% is class 1, we do upsampling of minority class\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VyTME1PIn_uA",
        "colab_type": "code",
        "outputId": "bcb6fa70-fbcb-43e8-b4d4-44d3ccb9f6f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "print('Before',np.shape(train))\n",
        "\n",
        "# Upsample\n",
        "\n",
        "from sklearn.utils import resample\n",
        "print(train.target.value_counts())\n",
        "df_majority = train[train.target==0]\n",
        "df_minority = train[train.target==1]\n",
        "\n",
        "# Upsample minority class\n",
        "df_minority_upsampled = resample(df_minority, \n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples=train.target.value_counts()[0]//2,    # to match majority class\n",
        "                                 random_state=42) # reproducible results\n",
        "\n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
        "\n",
        "# Display new class counts\n",
        "print('After')\n",
        "print(df_upsampled.target.value_counts())\n",
        "\n",
        "train=df_upsampled\n",
        "y=train.target\n",
        "# train=train.drop(['target'],axis=1)\n",
        "print(np.shape(train))\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before (144493, 184)\n",
            "0    96329\n",
            "1    48164\n",
            "Name: target, dtype: int64\n",
            "After\n",
            "0    96329\n",
            "1    48164\n",
            "Name: target, dtype: int64\n",
            "(144493, 184)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YZoMM5gDn_uB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# since features are anonymised into 3 categories, we split them into category-type\n",
        "\n",
        "ind_cols=[]\n",
        "reg_cols=[]\n",
        "car_cols=[]\n",
        "for e in train.columns:\n",
        "    if 'ind' in e:\n",
        "        ind_cols.append(e)\n",
        "    elif 'reg' in e:\n",
        "        reg_cols.append(e)\n",
        "    elif 'car' in e:\n",
        "        car_cols.append(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9SJxEAHTn_uC",
        "colab_type": "code",
        "outputId": "3fdf7635-5ddd-4ff9-8b1a-42a018fb2bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.shape(ind_cols),np.shape(reg_cols),np.shape(car_cols)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25,), (3,), (155,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qUUX5NbWn_uF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split each category into numeric or category\n",
        "\n",
        "ind_cols_cat=[]                      #### .   FOR THIS MODEL, WE INCLUDE ORDINAL IN CATEGORY COLS TO ENCODE THEM\n",
        "ind_cols_num=[]\n",
        "for f in ind_cols:\n",
        "    if 'bin' in f or f == 'target':\n",
        "        ind_cols_cat.append(f)\n",
        "    elif 'cat' in f or f == 'id':\n",
        "        ind_cols_cat.append(f)\n",
        "    elif df[f].dtype == float:\n",
        "        ind_cols_num.append(f)\n",
        "    elif df[f].dtype == int: ## INT are ordinal\n",
        "        ind_cols_cat.append(f)\n",
        "        \n",
        "        \n",
        "reg_cols_cat=[]\n",
        "reg_cols_num=[]\n",
        "for f in reg_cols:\n",
        "    if 'bin' in f or f == 'target':\n",
        "        reg_cols_cat.append(f)\n",
        "    elif 'cat' in f or f == 'id':\n",
        "        reg_cols_cat.append(f)\n",
        "    elif df[f].dtype == float:\n",
        "        reg_cols_num.append(f)\n",
        "    elif df[f].dtype == int:\n",
        "        reg_cols_cat.append(f)\n",
        "        \n",
        "        \n",
        "car_cols_cat=[]\n",
        "car_cols_num=[]\n",
        "for f in car_cols:\n",
        "    if 'bin' in f or f == 'target':\n",
        "        car_cols_cat.append(f)\n",
        "    elif 'cat' in f or f == 'id':\n",
        "        car_cols_cat.append(f)\n",
        "    elif df[f].dtype == float:\n",
        "        car_cols_num.append(f)\n",
        "    elif df[f].dtype == int:\n",
        "        car_cols_cat.append(f)\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mwFFbJYYn_uH",
        "colab_type": "code",
        "outputId": "a86199e8-5d43-415f-972a-e32f0b2271b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "all=[np.array(ind_cols_cat),np.array(ind_cols_num),np.array(reg_cols_cat),np.array(reg_cols_num),np.array(car_cols_cat),\n",
        "     np.array(car_cols_num)]\n",
        "for e in all:\n",
        "    print(np.shape(e))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25,)\n",
            "(0,)\n",
            "(0,)\n",
            "(3,)\n",
            "(151,)\n",
            "(4,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM6yJOQ8qT48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cat_cols=ind_cols_cat+reg_cols_cat+car_cols_cat\n",
        "nums_cols=ind_cols_num+reg_cols_num+car_cols_num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUEsFMkZqgLP",
        "colab_type": "code",
        "outputId": "99c5e477-226d-4861-d40c-9cad232bad00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(cat_cols),len(nums_cols)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(176, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itlbu3RDshLQ",
        "colab_type": "code",
        "outputId": "1fae02c5-5683-4ed5-c04d-6925ed9b92b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "g=[]\n",
        "for e in cat_cols:\n",
        "  g.append(np.shape(np.unique(train[e]))[0])\n",
        "#   print(e,np.shape(np.unique(train[e]))[0])\n",
        "np.unique(g)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2,  4,  5,  8, 12, 14])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PPE0iIimn_uQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class LoopDataset(Dataset):\n",
        "    \"\"\"Returns input_vals_cat as dict with column keys and numerics as tesnor\"\"\"\n",
        "    \n",
        "\n",
        "    def __init__(self, df,y,type=\"train\",pct=0.85): # \n",
        "\n",
        "        \n",
        "        N=np.shape(df)[0]\n",
        "        train_pct=int(pct*N)\n",
        "        val_pct=int((1-pct)*N)\n",
        "        \n",
        "        \n",
        "        if type==\"train\":\n",
        "            self.df=df.iloc[:train_pct,:]\n",
        "            self.y=y[:train_pct]\n",
        "        else:\n",
        "            self.df=df.iloc[-val_pct:,:]\n",
        "            self.y=y[-val_pct:]\n",
        "            \n",
        "            \n",
        "    def __len__(self):\n",
        "        return np.shape(self.df)[0]\n",
        "\n",
        "    def __getitem__(self, idx,cat_cols=cat_cols,nums_cols=nums_cols):\n",
        "      \n",
        "        input_vals_cat={}\n",
        "        for e in cat_cols:\n",
        "          input_vals_cat[e]= torch.tensor(self.df[e].iloc[idx]).long().unsqueeze(0)\n",
        "\n",
        "        input_num=[]\n",
        "        for e in nums_cols:\n",
        "          input_num.append(self.df[e].iloc[idx]) \n",
        "        input_num=torch.tensor(input_num) \n",
        "        \n",
        "        target=torch.tensor(self.y.iloc[idx])\n",
        "        \n",
        "        sample = {\"input_vals_cat\":input_vals_cat,\"input_num\":input_num,\"target\":target }\n",
        "        return sample\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNkhpv2Ridpr",
        "colab_type": "code",
        "outputId": "83cac87c-7648-4500-b6ec-ef687e150094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "# Model architecture : https://github.com/xiaozhouwang/kaggle-porto-seguro/blob/master/Jupyter_nnmodel/nn_model%20.ipynb\n",
        "# x_train is numeric cols which I pass through fc layers prior to merge due to larger count imbalance\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "Image(url= \"https://github.com/xiaozhouwang/kaggle-porto-seguro/raw/83d794f6dce63246aef67209bf596bdae54fea22/Jupyter_nnmodel/Jupyter_image/NN_layer.png\",width=900, height=400)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://github.com/xiaozhouwang/kaggle-porto-seguro/raw/83d794f6dce63246aef67209bf596bdae54fea22/Jupyter_nnmodel/Jupyter_image/NN_layer.png\" width=\"900\" height=\"400\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUi31SieHSwL",
        "colab_type": "text"
      },
      "source": [
        "1)\n",
        "- We put all category column names in a list. \n",
        "- Then we create an embedding layer for each of these depending upon thats feature's unique value count in a loop and store them in the dictionary self.cat_dict\n",
        "- Each embedding layer is saved in the dictionary according to its feature name so it can be retrieved later\n",
        "\n",
        "2)\n",
        "- We process the remaining numeric features through any number or size of fc layers given by fc_layers argument\n",
        "- This is done in part so thhe number of embeddings dont vastly outnumber numeric features\n",
        "\n",
        "3)\n",
        "- We then concatonate the embeddings and fc layers and pass through another set of fc layers of any number or size given by merge_layers argument\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Tanh is used for embedding layers while relu for all else\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Gvx4qKoUn_uQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class loop_embednet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self,df,fc_layers=[100,200,300],merge_layers=[512,64,1],small_embed=5,big_embed=9,cat_list=cat_cols,num_list=nums_cols):\n",
        "      \n",
        "        # df is train dataset\n",
        "        # fc_layers is sizes of fc layers for numeric excluding input size\n",
        "        # merge_layers is sizes of fc layers for concatonated embedding and fc_layer output excluding input size\n",
        "        # cat_list is list of category cols to create embedding layers for\n",
        "        # num_list is list of numeric cols to use for fc layers\n",
        "        \n",
        "        \n",
        "        super(loop_embednet, self).__init__()\n",
        "\n",
        "        \n",
        "        self.cat_list=cat_cols\n",
        "        self.num_list=num_list\n",
        "        merge_count=fc_layers[-1] # to count the inputs into first merge layer as total embedings + last fc\n",
        "        \n",
        "  \n",
        "        self.cat_dict={} # dict of embedding layers in a loop with key as feature_layer\n",
        "        \n",
        "        \n",
        "        \n",
        "        for e in cat_list:\n",
        "          unique=np.shape(np.unique(df[e]))[0] \n",
        "          embedding_dim = small_embed if np.shape(np.unique(df[e]))[0]==2 else big_embed # for binary use small_embed embeddings, else big_embed\n",
        "          self.cat_dict[e+'_layer']=torch.nn.Embedding(unique, embedding_dim) # save layer as feature name\n",
        "          merge_count+=embedding_dim\n",
        "          \n",
        "          \n",
        "                    \n",
        "          \n",
        "        self.fc_layers=fc_layers                  \n",
        "        self.fc_layers.insert(0, len(num_list) ) # add input size to first layer\n",
        "        \n",
        "        for i in range(len(self.fc_layers)-1):\n",
        "            setattr(self, 'fc'+str(i), torch.nn.Linear(self.fc_layers[i], self.fc_layers[i + 1]))\n",
        "            setattr(self, 'drop'+str(i), torch.nn.Dropout(p=0.5))\n",
        "            \n",
        "        \n",
        "               \n",
        "        \n",
        "        self.merge_layers=merge_layers                  \n",
        "        self.merge_layers.insert(0, merge_count ) # add input size as merge_count\n",
        "        \n",
        "        for i in range(len(self.merge_layers)-1):\n",
        "          setattr(self, 'merge'+str(i), torch.nn.Linear(self.merge_layers[i], self.merge_layers[i + 1]))\n",
        "          setattr(self, 'dropm'+str(i), torch.nn.Dropout(p=0.5))\n",
        "          \n",
        "\n",
        "\n",
        "    def forward(self, input_vals_cat,numeric_vals): \n",
        "      # input_vals_cat is dict with keys of category, and values as batches\n",
        "      # numeric is batch * concatonated vals of all numerics\n",
        "        \n",
        "        var = [] \n",
        "        for e in self.cat_list:\n",
        "          layer=self.cat_dict[e+'_layer']\n",
        "\n",
        "          layer_output=F.tanh(layer(input_vals_cat[e])) # Activation - tanh/relu\n",
        "          var.append( layer_output.view(layer_output.size(0), -1) )\n",
        "        \n",
        "                  \n",
        "\n",
        "        var_tensor = torch.cat(var,dim=1)\n",
        "    \n",
        "        for i in range(len(self.fc_layers)-1):\n",
        "          layer = getattr(self, 'fc'+str(i))\n",
        "          dropout=getattr(self, 'drop'+str(i))\n",
        "          numeric_vals = dropout(F.relu(layer (numeric_vals)))\n",
        "\n",
        "          \n",
        "        \n",
        "        merge=torch.cat((var_tensor,numeric_vals),dim=1)\n",
        "\n",
        "        \n",
        "        for i in range(len(self.merge_layers)-1):\n",
        "          layer = getattr(self, 'merge'+str(i) )\n",
        "          dropout=getattr(self, 'dropm'+str(i))\n",
        "          if i!=len(self.merge_layers)-2:merge = dropout(F.relu(layer (merge))) # if to prevent last output from relu\n",
        "          else: merge = layer (merge)\n",
        "            \n",
        "          \n",
        "\n",
        "          \n",
        "\n",
        "        \n",
        "        \n",
        "        return(merge)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBDeEW5a06HQ",
        "colab_type": "code",
        "outputId": "4ec1b388-1757-4e2d-f7c3-f22d74944b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")\n",
        "device"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sOzUC2t3n_uR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=loop_embednet(train,fc_layers=[32,64,128],merge_layers=[512,64,1]).to(device)\n",
        "\n",
        "for e in model.cat_dict.values():  # IMPORTANT, model.cuda() will not set dictionary list to cuda\n",
        "  e=e.to(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB2RebOr1Yoz",
        "colab_type": "code",
        "outputId": "5c88c520-6ef1-4946-ec37-e966bf026b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "model # The embedding layers will not be shown here as they are in a dict"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "loop_embednet(\n",
              "  (fc0): Linear(in_features=7, out_features=32, bias=True)\n",
              "  (drop0): Dropout(p=0.5)\n",
              "  (fc1): Linear(in_features=32, out_features=64, bias=True)\n",
              "  (drop1): Dropout(p=0.5)\n",
              "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
              "  (drop2): Dropout(p=0.5)\n",
              "  (merge0): Linear(in_features=1028, out_features=512, bias=True)\n",
              "  (dropm0): Dropout(p=0.5)\n",
              "  (merge1): Linear(in_features=512, out_features=64, bias=True)\n",
              "  (dropm1): Dropout(p=0.5)\n",
              "  (merge2): Linear(in_features=64, out_features=1, bias=True)\n",
              "  (dropm2): Dropout(p=0.5)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JPHc1FvRn_uR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs=192\n",
        "\n",
        "ds=LoopDataset(train,y)\n",
        "data_loader_train = DataLoader(ds, bs, shuffle=True, num_workers=2)\n",
        "\n",
        "ds_val=LoopDataset(train,y,type='val')\n",
        "data_loader_val = DataLoader(ds_val, bs, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "loaders={'train':data_loader_train,'val': data_loader_val}\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "izu5078Rn_uS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_lr=0.001\n",
        "binary_loss = torch.nn.BCELoss()\n",
        "\n",
        "sigmoid=torch.nn.Sigmoid()\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=init_lr,weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O-rJPnK6n_uU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def trainer_embed(model,epochs):\n",
        "    L=[]\n",
        "    V=[]\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        for e in loaders:\n",
        "            if e=='train':  model.train() ; grad=True \n",
        "            else: model.eval() ; grad=False\n",
        "\n",
        "            for idx, batch_data in enumerate(loaders[e]):\n",
        "              \n",
        "                for j in batch_data[\"input_vals_cat\"].keys():\n",
        "                  batch_data[\"input_vals_cat\"][j]=batch_data[\"input_vals_cat\"][j].to(device)\n",
        "                \n",
        "                target=Variable(batch_data['target']).float().to(device)\n",
        "                pred=model(batch_data['input_vals_cat'],batch_data['input_num'].to(device)) \n",
        "                \n",
        "                pred=sigmoid(pred)\n",
        "                loss=binary_loss(pred,target) \n",
        "                \n",
        "                \n",
        "                \n",
        "                if e=='train':\n",
        "                    L.append(loss.item())\n",
        "                    loss.backward()\n",
        "                    opt.step()\n",
        "                    opt.zero_grad()\n",
        "                    \n",
        "                    pred=pred.squeeze(1).detach().cpu().numpy()# for gini\n",
        "                    pred[pred<0.5]=0 \n",
        "                    pred[pred>0.5]=1\n",
        "                    \n",
        "#                     print('p',pred[:10],np.shape(pred))\n",
        "#                     print('t',target.detach().cpu().numpy()[:10],np.shape(target))\n",
        "                    print(e,'Epoch:',epoch,'Batch:',idx,'Loss:',sum(L)/len(L))#,'Gini:',eval_gini(target.detach().cpu().numpy(), pred))\n",
        "                    \n",
        "                    \n",
        "                else:\n",
        "                    V.append(loss.item())\n",
        "                    \n",
        "                    pred=pred.squeeze(1).detach().cpu().numpy()\n",
        "                    pred[pred<0.5]=0\n",
        "                    pred[pred>0.5]=1\n",
        "                    print(e,'Epoch:',epoch,'Batch:',idx,'Loss:',sum(V)/len(V),'Gini:',eval_gini(target.detach().cpu().numpy(), pred))\n",
        "    return(model,L,V)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "X5hEdtrOn_uW",
        "colab_type": "code",
        "outputId": "560a5837-f1fb-41ca-fc20-f0aebb5bf57b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        }
      },
      "source": [
        "model,L,V=trainer_embed(model,3)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train Epoch: 0 Batch: 0 Loss: 0.6674930453300476\n",
            "train Epoch: 0 Batch: 1 Loss: 0.6143832802772522\n",
            "train Epoch: 0 Batch: 2 Loss: 0.6055877208709717\n",
            "train Epoch: 0 Batch: 3 Loss: 0.6096152514219284\n",
            "train Epoch: 0 Batch: 4 Loss: 0.5965451002120972\n",
            "train Epoch: 0 Batch: 5 Loss: 0.5854047437508901\n",
            "train Epoch: 0 Batch: 6 Loss: 0.5773784262793404\n",
            "train Epoch: 0 Batch: 7 Loss: 0.577348954975605\n",
            "train Epoch: 0 Batch: 8 Loss: 0.5679308540291257\n",
            "train Epoch: 0 Batch: 9 Loss: 0.5604962170124054\n",
            "train Epoch: 0 Batch: 10 Loss: 0.5570675026286732\n",
            "train Epoch: 0 Batch: 11 Loss: 0.554887389143308\n",
            "train Epoch: 0 Batch: 12 Loss: 0.5551785001387963\n",
            "train Epoch: 0 Batch: 13 Loss: 0.5549834455762591\n",
            "train Epoch: 0 Batch: 14 Loss: 0.5524465123812358\n",
            "train Epoch: 0 Batch: 15 Loss: 0.5505609139800072\n",
            "train Epoch: 0 Batch: 16 Loss: 0.550558279542362\n",
            "train Epoch: 0 Batch: 17 Loss: 0.549064619673623\n",
            "train Epoch: 0 Batch: 18 Loss: 0.5477488103665804\n",
            "train Epoch: 0 Batch: 19 Loss: 0.5470860332250596\n",
            "train Epoch: 0 Batch: 20 Loss: 0.5462865006356012\n",
            "train Epoch: 0 Batch: 21 Loss: 0.5431750281290575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-c00a71675dc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-1e5680c78203>\u001b[0m in \u001b[0;36mtrainer_embed\u001b[0;34m(model, epochs)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_vals_cat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3ttpKvsHn_uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VBml5WKSn_uY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}